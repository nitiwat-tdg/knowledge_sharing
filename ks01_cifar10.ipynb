{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitiwat-tdg/knowledge_sharing/blob/main/ks01_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial modified form https://www.tensorflow.org/tutorials/images/cnn"
      ],
      "metadata": {
        "id": "3VyljSQNVliY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "gC_STA9AgBmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Iterator, Tuple\n",
        "from tensorflow.raw_ops import Softmax\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "\n",
        "# set seed\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "jpwbT7B1f_ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names\n",
        "\n",
        "CLASS_NAMES = [\n",
        "    'airplane',\n",
        "    'automobile',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'\n",
        "  ]"
      ],
      "metadata": {
        "id": "-T-_PhC0-7VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "0q4ubsRwAg-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset shape\n",
        "\n",
        "print(\"train_images.shape:\", train_images.shape)\n",
        "print(\"test_images.shape:\", test_images.shape)\n",
        "\n",
        "print(\"train_labels.shape:\", train_labels.shape)\n",
        "print(\"test_labels.shape:\", test_labels.shape)"
      ],
      "metadata": {
        "id": "onZfDjnFBpve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize label\n",
        "\n",
        "print(\"train_labels:\", train_labels)"
      ],
      "metadata": {
        "id": "PtGIhDHtB4h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Data\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    # The CIFAR labels happen to be arrays, \n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(CLASS_NAMES[train_labels[i][0]])\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-jxYMFlAigv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# Conv Layers + Pooling Layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "0o6Qd-zhAj55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5qBvSL8XAlkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "ZAXp3E4RVynY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and Train Model\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_images,\n",
        "    y=train_labels,\n",
        "    epochs=10, \n",
        "    validation_data=(test_images, test_labels)\n",
        "  )"
      ],
      "metadata": {
        "id": "Y-HEr6P1AsYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss and accuracy\n",
        "\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label = 'test_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'test_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# Print test accuracy\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "seIGUJVLAt_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Prediction\n",
        "\n",
        "def predict_single(model: tf.keras.Model, input: np.ndarray) -> int:\n",
        "  \"\"\"\n",
        "  predict single input \n",
        "  \"\"\"\n",
        "  pred_logits = model.predict(np.expand_dims(input, axis=0), verbose=0)\n",
        "  pred_id = np.argmax(pred_logits)\n",
        "  return pred_id\n",
        "\n",
        "\n",
        "# Visualize 25 test sample with image, prediction, labels\n",
        "plt.figure(figsize=(10,13))\n",
        "for i, (image, label) in enumerate(zip(test_images, test_labels)):\n",
        "    if i == 25:\n",
        "      break\n",
        "\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    pred_id = predict_single(model, image)\n",
        "    pred_class_name = CLASS_NAMES[pred_id]\n",
        "    label_class_name = CLASS_NAMES[label[0]]\n",
        "\n",
        "    plt.xlabel(\n",
        "        f\"pred: {pred_class_name}\\n label: {label_class_name}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "zzH8Gpwj_X7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions and labels all dataset\n",
        "\n",
        "def predict_batch(model: tf.keras.Model, inputs: np.ndarray) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  predict batch input\n",
        "  \"\"\"\n",
        "  pred_logits  = model.predict(inputs, verbose=0)\n",
        "  pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "  return pred_ids\n",
        "\n",
        "def get_batch_dataloader(x: np.ndarray, y: np.ndarray, batch_size: int) -> Iterator[Tuple[np.ndarray, np.ndarray]]:\n",
        "  \"\"\"\n",
        "  Generator that yield batch of input and label.\n",
        "  Each batch have N sample equal batch size\n",
        "  \"\"\"\n",
        "  lenght = math.ceil(len(y) / batch_size)\n",
        "  for i in range(lenght):\n",
        "    start_index = i * batch_size\n",
        "    end_index = (i + 1) * batch_size\n",
        "    batch_x = x[start_index: end_index]\n",
        "    batch_y = y[start_index: end_index].flatten()\n",
        "    yield batch_x, batch_y\n",
        "\n",
        "\n",
        "# create test_dataloder\n",
        "test_dataloader = get_batch_dataloader(x=test_images, y=test_labels, batch_size=32)\n",
        "\n",
        "# predict all data on test set\n",
        "y_trues = []\n",
        "y_preds = []\n",
        "for i, (x, y) in enumerate(test_dataloader):\n",
        "  y_trues.extend(y)\n",
        "  batch_prediction = predict_batch(model=model, inputs=x)\n",
        "  y_preds.extend(batch_prediction)\n"
      ],
      "metadata": {
        "id": "i-zSsm4YA2ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display confusion matrix \n",
        "\n",
        "cm = confusion_matrix(y_true=y_trues, y_pred=y_preds)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=CLASS_NAMES)\n",
        "fig, ax = plt.subplots(figsize=(11, 11))\n",
        "disp.plot(ax=ax)"
      ],
      "metadata": {
        "id": "6Zz9RI29ITC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display classification report\n",
        "\n",
        "y_trues_name = [CLASS_NAMES[y_true] for y_true in y_trues]\n",
        "y_preds_name = [CLASS_NAMES[y_pred] for y_pred in y_preds]\n",
        "report = classification_report(y_true=y_trues_name, y_pred=y_preds_name, labels=CLASS_NAMES)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "CFt8Y5WdGWzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}